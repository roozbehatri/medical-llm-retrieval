{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49c71a0-14e3-4f93-b718-3677a6265ddc",
   "metadata": {},
   "source": [
    "# What This Notebook Does:\n",
    "\n",
    "1. Loads the Vector Store\n",
    "\t* It loads the FAISS index you created earlier (which contains the embeddings of the chunked chest X-ray reports).\n",
    "\t* This index allows for fast similarity search to find relevant text chunks based on a user’s query.\n",
    "\n",
    "\n",
    "2. Sets Up a Retriever\n",
    "\t* The retriever searches the vector store to find the most similar chunks to the user’s question.\n",
    "\t* In this case, we retrieve the top 3 relevant text chunks.\n",
    "\n",
    "3. Connects to the LLM\n",
    "\t* The retriever passes the most relevant chunks to an OpenAI GPT model via the LangChain RetrievalQA chain.\n",
    "\t* The model generates a final answer based on the retrieved context.\n",
    "\n",
    "4. Builds the RetrievalQA Pipeline\n",
    "\t*\tThis combines:\n",
    "\t*\tThe retriever (retrieves relevant chunks)\n",
    "\t*\tThe LLM (generates an answer)\n",
    "\t*\tThe return_source_documents=True setting also shows which chunks were used to answer the question, giving you full transparency.\n",
    "\n",
    "5. Tests the System\n",
    "\t* Provide natural language questions like: “What are the key findings in this chest X-ray report?”\n",
    "\t* The system:\n",
    "    \t- Retrieves relevant text from the dataset\n",
    "    \t- Generates a concise answer\n",
    "    \t- Displays the answer and the supporting source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5cff67-4704-4761-8ab1-a224a24d1e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Load vector store from disk (trusted local file)\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"../results/faiss_vectorstore\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7211a2-0979-4df5-a0d5-8719a5b9bd4a",
   "metadata": {},
   "source": [
    "# Set Up Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d426c24a-b997-4c3f-b335-d8ee35097f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d3df53-e255-4b40-ba98-c35a84cab429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71030b-3c9b-49e4-ada5-2eb48c828a12",
   "metadata": {},
   "source": [
    "# Build the RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ae8e78-e4b6-441e-950f-514e77e95dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c112a-60ab-4802-a865-a7baf28610c3",
   "metadata": {},
   "source": [
    "# Test the QA System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876ac6b6-3fd4-4115-948f-940bb46d1527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/84z7b4x12wx_79w4qn7byb2h0000gn/T/ipykernel_86399/813145135.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The key findings in this chest X-ray include a small stable foreign body in the left chest, vascular calcifications in the aortic XXXX, mild degenerative changes of the spine, sclerotic lesions within the XXXX, several bilateral rib fractures with evidence of callus formation, and calcified subcarinal and right hilar lymph XXXX. There is also a vague nodular opacity in the right midlung that may be an artifact.\n",
      "\n",
      "Sources:\n",
      "{'source': 'report_2234'}\n",
      "{'source': 'report_2154'}\n",
      "{'source': 'report_136'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the key findings in this chest X-ray?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(result['result'])\n",
    "\n",
    "print(\"\\nSources:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd0908-d8ce-46f1-9372-996684df2890",
   "metadata": {},
   "source": [
    "# RetrievalQA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2339e5-01f6-412c-be52-495bc4c885bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up the Retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "# k=3 → Retrieves the top 3 most relevant chunks\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "#  Build the RetrievalQA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b7db3d-58e5-4939-842c-19156288f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The key findings in this chest X-ray report include a small stable foreign body over the left chest, vascular calcifications over the aortic XXXX, mild degenerative changes of the spine, sclerotic lesions within the XXXX, several bilateral rib fractures with evidence of callus formation, and normal heart, pulmonary XXXX, and mediastinum.\n",
      "\n",
      "Sources:\n",
      "Source: {'source': 'report_2234'}\n",
      "Content: The heart, pulmonary XXXX and mediastinum are within normal limits. There is no pleural effusion or pneumothorax. There is no focal air space opacity to suggest a pneumonia. There is a small stable XX\n",
      "----------------------------------------\n",
      "Source: {'source': 'report_2154'}\n",
      "Content: The lungs are clear. No suspicious pulmonary mass or nodule is identified. There is no pleural effusion or pneumothorax. Heart size and mediastinal contour are normal. There are sclerotic lesions with\n",
      "----------------------------------------\n",
      "Source: {'source': 'report_2356'}\n",
      "Content: The heart, pulmonary XXXX and mediastinum are within normal limits. There is no pleural effusion or pneumothorax. There is no focal air space opacity to suggest a pneumonia. Both clavicles appear with\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with Example Query\n",
    "query = \"What are the key findings in this chest X-ray report?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(result['result'])\n",
    "\n",
    "print(\"\\nSources:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\"Source: {doc.metadata}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}\")  # Print first 200 chars\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c9dcb-f5f8-4b11-8f29-8992e99aeeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
